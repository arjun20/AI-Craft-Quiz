{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17de9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16489aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94ec3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arjun/Desktop/MCQ Generator/experiment\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd94dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY: 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\n"
     ]
    }
   ],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API KEY:\", KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07649343",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd60d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcqs': [{'question': 'multiple choice question', 'options': {'A': 'choice here', 'B': 'choice here', 'C': 'choice here', 'D': 'choice here'}, 'correct_option': 'A'}, {'question': 'multiple choice question', 'options': {'A': 'choice here', 'B': 'choice here', 'C': 'choice here', 'D': 'choice here'}, 'correct_option': 'C'}, {'question': 'multiple choice question', 'options': {'A': 'choice here', 'B': 'choice here', 'C': 'choice here', 'D': 'choice here'}, 'correct_option': 'B'}]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/arjun/Desktop/MCQ Generator/experiment/Response.json\", \"r\") as f:\n",
    "    RESPONSE_JSON = json.load(f)\n",
    "\n",
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e6d1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "You are an expert at designing multiple choice questions (MCQs).\n",
    "\n",
    "Given the **text** below, your task is to generate **{number} unique MCQs** for students studying **{subject}**. The quiz should be written in a **{tone} tone**.\n",
    "\n",
    "Make sure:\n",
    "- All questions are relevant to the provided text\n",
    "- No questions are repeated\n",
    "- Each question has 4 answer choices (A–D)\n",
    "- Exactly one correct answer is marked\n",
    "- All questions are clear and unambiguous\n",
    "\n",
    "---\n",
    "### TEXT:\n",
    "{text}\n",
    "---\n",
    "\n",
    "### REQUIRED FORMAT (RESPONSE_JSON):\n",
    "{RESPONSE_JSON}\n",
    "\n",
    "Please strictly follow the JSON structure above and ensure it contains exactly {number} MCQs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "205dc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8cdf3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain= LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14027787",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian and question designer.\n",
    "\n",
    "Your task is to review the following Multiple Choice Quiz intended for {subject} students. Perform the following:\n",
    "\n",
    "1. **Complexity Analysis**  \n",
    "   - Evaluate the overall language complexity and cognitive demand of each question.  \n",
    "   - Use no more than **50 words** in total for the complexity analysis.  \n",
    "\n",
    "2. **Suitability Check**  \n",
    "   - Determine whether the questions are appropriate for the cognitive and analytical level of {subject} students.  \n",
    "   - If any questions are **too simple, too complex, or grammatically incorrect**, rewrite them accordingly.  \n",
    "   - Maintain clarity and pedagogical soundness.  \n",
    "\n",
    "---\n",
    "### Original Quiz\n",
    "{quiz}\n",
    "---\n",
    "\n",
    "### Output Format\n",
    "\n",
    "Please return the following:\n",
    "- **Complexity_Analysis**: A short summary (≤ 50 words).\n",
    "- **Updated_Quiz**: A revised version of the MCQs if needed, in the same structure as the input.\n",
    "- **Suggestions**: Optional brief notes on why any changes were made.\n",
    "\n",
    "Start your response below:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cad3ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e064f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluation_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"RESPONSE_JSON\"],\n",
    "    output_variables=[\"review\", \"quiz\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3846495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arjun/Desktop/MCQ Generator/data.txt\n"
     ]
    }
   ],
   "source": [
    "file_path=r\"/Users/arjun/Desktop/MCQ Generator/data.txt\"\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3396f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to review the following Multiple Choice Quiz intended for {subject} students. Perform the following:\n",
      "\n",
      "1. **Complexity Analysis**  \n",
      "   - Evaluate the overall language complexity and cognitive demand of each question.  \n",
      "   - Use no more than **50 words** in total for the complexity analysis.  \n",
      "\n",
      "2. **Suitability Check**  \n",
      "   - Determine whether the questions are appropriate for the cognitive and analytical level of {subject} students.  \n",
      "   - If any questions are **too simple, too complex, or grammatically incorrect**, rewrite them accordingly.  \n",
      "   - Maintain clarity and pedagogical soundness.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    TEXT = file.read()\n",
    "\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1000c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RESPONSE_JSON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m SUBJECT= \u001b[33m\"\u001b[39m\u001b[33mAI\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m TONE=\u001b[33m\"\u001b[39m\u001b[33mSimple\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m RESPONSE_JSON=RESPONSE_JSON\n",
      "\u001b[31mNameError\u001b[39m: name 'RESPONSE_JSON' is not defined"
     ]
    }
   ],
   "source": [
    "TEXT,\n",
    "NUMBER= 10,\n",
    "SUBJECT= \"AI\",\n",
    "TONE=\"Simple\"\n",
    "RESPONSE_JSON=RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba35f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"mcqs\": [{\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct_option\": \"A\"}, {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct_option\": \"C\"}, {\"question\": \"multiple choice question\", \"options\": {\"A\": \"choice here\", \"B\": \"choice here\", \"C\": \"choice here\", \"D\": \"choice here\"}, \"correct_option\": \"B\"}]}'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data = json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f445af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_openai_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[32m      2\u001b[39m     respose = generate_evaluation_chain(\n\u001b[32m      3\u001b[39m         {\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m:TEXT, \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         }\n\u001b[32m     10\u001b[39m     )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(respose)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_openai_callback' is not defined"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    respose = generate_evaluation_chain(\n",
    "        {\n",
    "        \"text\":TEXT, \n",
    "        \"number\":NUMBER,\n",
    "        \"subject\":SUBJECT, \n",
    "        \"tone\":TONE, \n",
    "        \"RESPONSE_JSON\":json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(respose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8976c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 0\n",
      "Prompts Tokens: 0\n",
      "Completion Tokens: 0\n",
      "Total Cost: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "print(f\"Prompts Tokens: {cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "print(f\"Total Cost: {cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b15710c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'respose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quiz = respose.get(\u001b[33m\"\u001b[39m\u001b[33mquiz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m quiz = json.load(quiz)\n",
      "\u001b[31mNameError\u001b[39m: name 'respose' is not defined"
     ]
    }
   ],
   "source": [
    "quiz = respose.get(\"quiz\")\n",
    "\n",
    "quiz = json.load(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c25c8ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quiz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m quiz_table_data = []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m quiz.items():\n\u001b[32m      3\u001b[39m     mcq = value[\u001b[33m\"\u001b[39m\u001b[33mmcq\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m     options = \u001b[33m\"\u001b[39m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m      5\u001b[39m         [\n\u001b[32m      6\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moption\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moption_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m option, option_value \u001b[38;5;129;01min\u001b[39;00m value[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m].items()\n\u001b[32m      8\u001b[39m             ]\n\u001b[32m      9\u001b[39m         )\n",
      "\u001b[31mNameError\u001b[39m: name 'quiz' is not defined"
     ]
    }
   ],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a13053",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"machinelearning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ce838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE=\"{datetime.now().strftime('%m_%d_%Y_%H_%M_%S')}.log\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstGenAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
